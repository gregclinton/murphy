{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from numpy.linalg import inv\n",
    "from sigmoid import sigmoid\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = 1.0 * np.random.choice(2, size = 200)\n",
    "mvn = stats.multivariate_normal.rvs\n",
    "X = np.array([mvn([1, 1] if heads else [4, 4]) for heads in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    N, D = X.shape\n",
    "    w = np.zeros(D)\n",
    "    ybar = np.mean(y)\n",
    "    w0 = np.log(ybar / (1 - ybar))\n",
    "\n",
    "    for k in range(2):\n",
    "        eta = w0 + X.dot(w)\n",
    "        mu = sigmoid(eta)\n",
    "        s = mu * (1 - mu)\n",
    "        z = eta + (y - mu) / s\n",
    "        S = np.diag(s)\n",
    "        w = inv(X.T.dot(S).dot(X)).dot(X.T).dot(z)    \n",
    "    return w0, w\n",
    "\n",
    "def predict(model, X):\n",
    "    w0, w = model\n",
    "    return (sigmoid(w0 + X.dot(w)) > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    N, D = X.shape\n",
    "    \n",
    "    def NLL(w):\n",
    "        muw = mu(w)\n",
    "        return -sum(y * np.log(muw) + (1 - y) * np.log(1 - muw))\n",
    "\n",
    "    mu = lambda w: sigmoid(X.dot(w))\n",
    "    jac = lambda w: X.T.dot(mu(w) - y)\n",
    "    S = lambda w, mu: np.diag(mu * (1 - mu))\n",
    "    hess = lambda w: X.T.dot(S(w, mu(w))).dot(X)\n",
    "\n",
    "    w = np.ones(D)\n",
    "    return minimize(NLL, w, jac = jac, hess = hess, method = 'Newton-CG').x\n",
    "\n",
    "def predict(model, X):\n",
    "    w = model\n",
    "    X.dot(w)\n",
    "    return (sigmoid(X.dot(w)) > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit(X, y):\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "def predict(model, X):\n",
    "    clf = model\n",
    "    return (clf.predict(X) > 0.5) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98499999999999999"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y == predict(fit(X, y), X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
