{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "datasets.downloads = '/users/gregc/Downloads/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trX, teX, trY, teY = datasets.mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode = lambda p: np.argmax(p, axis = 1) \n",
    "accuracy = lambda p, Y: np.mean(decode(p) == decode(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def dense(output_dim, x):\n",
    "    shape = (x.get_shape()[1].value, output_dim)\n",
    "    w = tf.Variable(tf.random_normal_initializer(0.0, 0.05)(shape))\n",
    "    b = tf.Variable(tf.zeros(shape[1], dtype = tf.float32))\n",
    "    return tf.matmul(x, w) + b  \n",
    "    \n",
    "def fit(sess, x, y, X, Y, optimizer, epochs):\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    N, D = X.shape\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for start in range(0, N - 32, 32):\n",
    "            end = start + 32\n",
    "            feed_dict = {x: X[start : end], y: Y[start : end]}\n",
    "            sess.run(optimizer, feed_dict = feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9531\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, (None, trX.shape[1]))\n",
    "y = tf.placeholder(tf.float32)\n",
    "h = tf.nn.relu(dense(625, x))  \n",
    "model = dense(trY.shape[1], h)\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits(model, y)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    fit(sess, x, y, trX, trY, optimizer, epochs = 1)\n",
    "    print accuracy(model.eval({x: teX}), teY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 32s - loss: 0.1944    \n",
      "0.9691\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim = 625, input_dim = trX.shape[1], activation = 'relu'))\n",
    "model.add(Dense(output_dim = trY.shape[1], activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
    "model.fit(trX, trY, nb_epoch = 1)\n",
    "print accuracy(model.predict_proba(teX, verbose = 0), teY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = model.get_config()\n",
    "weights = model.get_weights()\n",
    "\n",
    "model = Sequential.from_config(config)\n",
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.547891156463\n"
     ]
    }
   ],
   "source": [
    "# http://iamtrask.github.io/2015/07/12/basic-python-network/\n",
    "\n",
    "X, y = datasets.htwt()\n",
    "y = np.array([y]).T\n",
    "\n",
    "# X = np.array([ [0, 0, 1],[0, 1, 1],[1, 0, 1],[1, 1, 1] ])\n",
    "# y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "epochs = 10000\n",
    "learning_rate = 0.00001\n",
    "\n",
    "N, D = X.shape\n",
    "\n",
    "W0 = 2 * np.random.random((D, N)) - 1\n",
    "W1 = 2 * np.random.random((N, 1)) - 1\n",
    "\n",
    "for j in xrange(epochs):\n",
    "    l1 = 1 / (1 + np.exp(-(np.dot(X, W0))))\n",
    "    l2 = 1 / (1 + np.exp(-(np.dot(l1, W1))))\n",
    "    l2_delta = (y - l2) * (l2 * (1 - l2))\n",
    "    l1_delta = l2_delta.dot(W1.T) * (l1 * (1 - l1))\n",
    "    W1 += l1.T.dot(l2_delta) * learning_rate\n",
    "    W0 += X.T.dot(l1_delta) * learning_rate\n",
    "    \n",
    "print np.mean((l2.T[0] > 0.5) * 1 == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyDense:\n",
    "    def __init__(self, output_dim, X):\n",
    "        self.X = X\n",
    "        self.W = np.random.normal(0, 0.05, (output_dim, X.shape[1]))\n",
    "        self.b = np.zeros((output_dim, 1))\n",
    "        self.shape = X.shape\n",
    "        \n",
    "    def forward(self):\n",
    "        self.eta = self.W.dot(X.T) + np.tile(self.b, (1, self.X.shape[0]))\n",
    "\n",
    "    def back(self):\n",
    "        pass\n",
    "\n",
    "    def update(self):\n",
    "        pass\n",
    "\n",
    "X = np.array([[1, 1], [0, 2], [4, 3]])\n",
    "        \n",
    "dense = MyDense(100, X)\n",
    "dense.forward()\n",
    "# dense.eta"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
