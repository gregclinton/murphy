{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datasets\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import log_loss\n",
    "from softmax import softmax, log_softmax\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = datasets.htwt()\n",
    "Y = datasets.one_hot(y)\n",
    "N, D = X.shape\n",
    "N, C = Y.shape\n",
    "Xaug = np.hstack([np.ones((N, 1)), X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = T.dvector()\n",
    "decode = lambda params: (params[1:].reshape((D, 1)), params[0])\n",
    "mu = lambda w, b: T.nnet.sigmoid(T.dot(X, w) + b)\n",
    "loss = T.sum(T.nnet.binary_crossentropy(mu(*decode(z)), y.reshape((N, 1))))\n",
    "grad = theano.function([z], T.grad(loss, z))\n",
    "hess = theano.function([z], T.hessian(loss, z))\n",
    "loss = theano.function([z], loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = lambda w: expit(Xaug.dot(w))\n",
    "loss = lambda w: log_loss(y, mu(w), normalize = False)\n",
    "grad = lambda w: Xaug.T.dot(mu(w) - y)\n",
    "S = lambda mu: np.diag(mu * (1 - mu))\n",
    "hess = lambda w: Xaug.T.dot(S(mu(w))).dot(Xaug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.119\n"
     ]
    }
   ],
   "source": [
    "params = [0] * (D + 1)\n",
    "w = minimize(loss, params).x\n",
    "w = minimize(loss, params, method = 'Newton-CG', jac = grad, hess = hess, tol = 1e-6).x\n",
    "yhat = expit(Xaug.dot(w)) > 0.5\n",
    "print '%0.3f' % np.mean(yhat != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode = lambda params: params.reshape((D + 1, C))\n",
    "z = T.dvector()\n",
    "mu = lambda W: T.nnet.softmax(T.dot(Xaug, W))\n",
    "loss = T.sum(T.nnet.categorical_crossentropy(mu(decode(z)), Y))\n",
    "grad = theano.function([z], T.grad(loss, z))\n",
    "hess = theano.function([z], T.hessian(loss, z))    \n",
    "loss = theano.function([z], loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decode = lambda params: np.array(params).reshape((D + 1, C))\n",
    "\n",
    "mu = lambda W: softmax(Xaug.dot(W))\n",
    "loss = lambda params: log_loss(y, mu(decode(params)), normalize = False)\n",
    "\n",
    "def grad(params):\n",
    "    Z = mu(decode(params)) - Y\n",
    "    return sum([np.kron(Xaug[i], z) for i, z in enumerate(Z)])\n",
    "\n",
    "def hess(params):\n",
    "    Mu = mu(decode(params))\n",
    "    o = lambda x: np.outer(x, x)\n",
    "    return sum([np.kron(o(Xaug[i]), np.diag(z) - o(z)) for i, z in enumerate(Mu)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.114\n"
     ]
    }
   ],
   "source": [
    "params = [0] * (D + 1) * C\n",
    "params = minimize(loss, params, method = 'Newton-CG', jac = grad, hess = hess, tol = 1e-6).x\n",
    "W = params.reshape((D + 1, C))\n",
    "yhat = np.argmax(softmax(Xaug.dot(W)), axis = 1)\n",
    "print '%0.3f' % np.mean(yhat != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-35.72143655,   0.40408765,   0.05280663])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvn = stats.multivariate_normal\n",
    "log_prior = lambda w: mvn.logpdf(w[1:], np.zeros(D), 100 * np.eye(D))\n",
    "mu = lambda w: expit(Xaug.dot(w))\n",
    "nll = lambda w: log_loss(y, mu(w), normalize = False)\n",
    "E = lambda w: nll(w) - log_prior(w)\n",
    "params = np.zeros(D + 1)\n",
    "w_hat = minimize(E, params).x\n",
    "S = lambda mu: np.diag(mu * (1 - mu))\n",
    "H = Xaug.T.dot(S(mu(w_hat))).dot(Xaug) + 1.0 / 200\n",
    "posterior = mvn(w_hat, inv(H))\n",
    "posterior.rvs()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
